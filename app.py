# app.py  (Streamlit + Telethon + Ù†ØªÙŠØ¬Ø© ÙˆØ§Ø­Ø¯Ø© + Ø¨Ø­Ø« Ø¯Ø§Ø®Ù„ Ø£ÙŠ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ)
import streamlit as st
from telethon.sync import TelegramClient
from telethon.tl.types import InputMessagesFilterDocument
import asyncio
import unicodedata

# ---------- Ø§Ù„Ø£Ø³Ø±Ø§Ø± (Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Streamlit) ----------
api_id   = int(st.secrets["api_id"])
api_hash = st.secrets["api_hash"]
bot_token = st.secrets["bot_token"]
channel_id = int(st.secrets["channel_id"])

# ---------- ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ ----------
def normalize_arabic(text: str) -> str:
    if not text: return ""
    text = unicodedata.normalize("NFKC", text)
    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
    hamza = "Ø¡"
    for k, v in {"Ø£":"Ø§", "Ø¥":"Ø§", "Ø¦":hamza, "Ø¤":hamza, "Ø¡":hamza}.items():
        text = text.replace(k, v)
    return text.replace("Ù‰", "ÙŠ").strip()

# ---------- Ø¬Ù„Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ----------
async def fetch_books(keyword: str, limit: int = 20):
    client = TelegramClient("bot_session", api_id, api_hash",
                            connection_retries=2, request_retries=2, timeout=10)
    await client.start(bot_token=bot_token)
    keyword_norm = normalize_arabic(keyword)
    results = []
    async for msg in client.iter_messages(
        channel_id,
        filter=InputMessagesFilterDocument(),
        limit=limit
    ):
        if msg.document:
            msg_text_norm = normalize_arabic(msg.message or "")
            file_name = msg.document.attributes[0].file_name if msg.document.attributes else ""
            file_text_norm = normalize_arabic(file_name)

            if keyword_norm in msg_text_norm or keyword_norm in file_text_norm:
                results.append({
                    "title": msg.message or "Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†",
                    "file_name": file_name or "unknown",
                    "size": msg.document.size,
                    "date": msg.date
                })
    await client.disconnect()
    return results

# ---------- ÙˆØ§Ø¬Ù‡Ø© Streamlit ----------
st.set_page_config(page_title="Ù…Ø­Ø±Ù‘Ùƒ ÙƒØªØ¨ÙŠ", layout="centered")
st.title("ğŸ” Ù…Ø­Ø±Ù‘Ùƒ ÙƒØªØ¨ÙŠ")
st.markdown("Ø§Ø¨Ø­Ø« ÙÙŠ Ù…ÙƒØªØ¨ØªÙƒ Ø§Ù„ØªÙ„ØºØ±Ø§ÙÙŠØ© Ø¯ÙˆÙ† Ø§Ù„Ù‚Ù„Ù‚ Ù…Ù† Ø§Ù„Ù‡Ù…Ø²Ø§Øª Ø£Ùˆ Ø§Ù„ØªØ´ÙƒÙŠÙ„.")

keyword = st.text_input("Ø§ÙƒØªØ¨ Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ø£Ùˆ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ©:")
if st.button("Ø¨Ø­Ø«"):
    if not keyword.strip():
        st.warning("Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø© Ù„Ù„Ø¨Ø­Ø«!")
    else:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
            try:
                hits = asyncio.run(fetch_books(keyword))
            except Exception as e:
                st.error(f"âš ï¸ ØªØ¹Ø°Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Telegram Ø­Ø§Ù„ÙŠØ§Ù‹.\nØ§Ù„Ø®Ø·Ø£:\n{e}")
                st.stop()

        if not hits:
            st.info("Ù„Ù… ÙŠÙØ¹Ø«Ø± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬.")
        else:
            st.success(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(hits)} Ù†ØªÙŠØ¬Ø©")
            for h in hits:
                sz_mb = h["size"] / 1024 / 1024
                date_str = h["date"].strftime("%Y-%m-%d")
                with st.expander(f"{h['title']}  â€“  {sz_mb:.2f} Ù…ÙŠØ¬Ø§"):
                    st.write(f"**Ø§Ù„Ù…Ù„Ù:** {h['file_name']}")
                    st.write(f"**Ø§Ù„ØªØ§Ø±ÙŠØ®:** {date_str}")
